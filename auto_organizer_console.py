#!/usr/bin/env python3
"""
ìŠ¤íŠœë””ì˜¤ìƒì¼ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ v6.0
- êµ¬ê¸€ ìº˜ë¦°ë” â†’ êµ¬ê¸€ ì‹œíŠ¸ ìë™ ë“±ë¡ (ì‹ ê·œ)
- ì›ë³¸/ë‚´ë³´ë‚´ê¸° ì •ë¦¬
- ë² ì´ì§/í”„ë¦¬ë¯¸ì—„ ì‹œíŠ¸ ë¶„ë¦¬ ìš´ì˜
- ë² ì´ì§: ì›ë³¸ ZIP â†’ ì—…ë¡œë“œ â†’ ë°œì†¡
- í”„ë¦¬ë¯¸ì—„: 1ì°¨(ì›ë³¸+êµ¬ê¸€í¼) / 2ì°¨(ë³´ì •ë³¸) ë°œì†¡
- EXIF ì´¬ì˜ì¼ ê²€ì¦ (90% ê¸°ì¤€)
- Drive/Sheets: OAuth í† í° ë°©ì‹ (bdayyatap@gmail.com)
- Firebase Storage: bdaystudio.store API ê²½ìœ 
"""

import os
import sys
import json
import re
import shutil
import zipfile
import pickle
import logging
import requests
import firebase_admin
from firebase_admin import credentials as fb_credentials, storage as fb_storage
from pathlib import Path
from datetime import datetime, timedelta, timezone
from PIL import Image
from PIL.ExifTags import TAGS

from google.oauth2.service_account import Credentials as ServiceCredentials
from google.oauth2.credentials import Credentials as OAuthCredentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build

# ============================================================
# ì„¤ì •
# ============================================================
ORIGINAL_FOLDER = Path('/volume2/photo/BDAY-STUDIO/C/Original/ì›ë³¸ì‚¬ì§„')
EXPORT_FOLDER = Path('/volume2/photo/BDAY-STUDIO/C/Users/zepss/Desktop/ë‚´ë³´ë‚´ê¸°')
CLIENTS_FOLDER = Path('/volume2/photo/BDAY-STUDIO/C/Console')
PREMIUM_FOLDER = Path('/volume2/photo/WORK/01 í”„ë¦¬ë¯¸ì—„ ê³ ê°')
PREMIUM_DONE_FOLDER = PREMIUM_FOLDER / '01 ë°œì†¡ì™„ë£Œ'
ORIGINAL_BASE = Path('/volume2/photo/BDAY-STUDIO/C/Original/ì›ë³¸ì‚¬ì§„')
RETOUCH_SUBFOLDER = 'ë³´ì •ë³¸'

CREDENTIALS_FILE = Path.home() / 'studio_automation' / 'scripts' / 'credentials.json'
TOKEN_FILE = Path.home() / 'studio_automation' / 'scripts' / 'drive_token.pickle'
CONFIG_FILE = Path.home() / 'studio_automation' / 'scripts' / 'config.json'
LOG_FILE = Path('/var/services/homes/jin/studio_automation/logs/auto_organizer.log')
LOCK_FILE = Path('/var/services/homes/jin/studio_automation/scripts/auto_organizer.lock')
CALENDAR_ID = 'bdayyatap@gmail.com'

PAST_HOURS_LIMIT = 6
TIME_BUFFER_MINUTES = 10
KST = timezone(timedelta(hours=9))

# ì‹œíŠ¸ ë²”ìœ„ (ê¸°ì¡´ ì‹œíŠ¸1ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
BASIC_SHEET_RANGE = 'ë² ì´ì§!A2:F1000'
PREMIUM_SHEET_RANGE = 'í”„ë¦¬ë¯¸ì—„!A2:J1000'

SCOPES_CALENDAR = ['https://www.googleapis.com/auth/calendar.readonly']
SCOPES_OAUTH = [
    'https://www.googleapis.com/auth/spreadsheets'
]

# ============================================================
# ë¡œê¹… ì„¤ì •
# ============================================================
LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(str(LOG_FILE), encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# ì„¤ì • íŒŒì¼ ë¡œë“œ
# ============================================================
def load_config():
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

# ============================================================
# API ì„œë¹„ìŠ¤ ìƒì„±
# ============================================================
def get_calendar_service():
    creds = ServiceCredentials.from_service_account_file(
        str(CREDENTIALS_FILE), scopes=SCOPES_CALENDAR
    )
    service = build('calendar', 'v3', credentials=creds, cache_discovery=False)
    logger.info("Google Calendar API ì—°ê²° ì„±ê³µ")
    return service

def get_oauth_credentials():
    creds = None
    if TOKEN_FILE.exists():
        with open(TOKEN_FILE, 'rb') as f:
            creds = pickle.load(f)
    if creds and creds.expired and creds.refresh_token:
        logger.info("OAuth í† í° ê°±ì‹  ì¤‘...")
        creds.refresh(Request())
        with open(TOKEN_FILE, 'wb') as f:
            pickle.dump(creds, f)
        logger.info("OAuth í† í° ê°±ì‹  ì™„ë£Œ")
    if not creds or not creds.valid:
        error_msg = "OAuth í† í°ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë§¥ë¯¸ë‹ˆì—ì„œ í† í°ì„ ì¬ìƒì„±í•´ì•¼ ìë™í™”ê°€ ì¬ê°œë©ë‹ˆë‹¤."
        logger.error(error_msg)
        try:
            config = load_config()
            notify_error(config, "ì¸ì¦ ë„êµ¬", error_msg)
        except:
            pass
        return None
    return creds

def get_sheets_service():
    creds = get_oauth_credentials()
    if not creds:
        raise Exception("OAuth ì¸ì¦ ì‹¤íŒ¨")
    sheets_service = build('sheets', 'v4', credentials=creds, cache_discovery=False)
    logger.info("Google Sheets API ì—°ê²° ì„±ê³µ (OAuth)")
    return sheets_service

def init_firebase():
    """Firebase Admin SDK ì´ˆê¸°í™”"""
    if firebase_admin._apps:
        return fb_storage.bucket()
    
    scripts_dir = Path.home() / 'studio_automation' / 'scripts'
    pid = (scripts_dir / 'fb_project_id.txt').read_text().strip()
    email = (scripts_dir / 'fb_client_email.txt').read_text().strip()
    pk = (scripts_dir / 'fb_private_key.txt').read_text().strip().replace('\\n', '\n')
    
    cred = fb_credentials.Certificate({
        'type': 'service_account',
        'project_id': pid,
        'client_email': email,
        'private_key': pk,
        'token_uri': 'https://oauth2.googleapis.com/token'
    })
    firebase_admin.initialize_app(cred, {'storageBucket': pid + '.firebasestorage.app'})
    bucket = fb_storage.bucket()
    logger.info(f"Firebase Storage ì—°ê²° ì„±ê³µ: {bucket.name}")
    return bucket

# ============================================================
# ë³´ì¡° í•¨ìˆ˜
# ============================================================
def sanitize_customer_name(name):
    if not name:
        return "unknown"
    clean = re.sub(r'\(.*?\)', '', name).strip()
    clean = re.sub(r'[^\wê°€-í£a-zA-Z0-9 ]', '', clean).strip()
    return clean if clean else "unknown"

def normalize_date(date_str):
    """'2026. 2. 13' â†’ '260213'"""
    parts = re.split(r'[\./\-\s]+', date_str.strip())
    parts = [p for p in parts if p]
    if len(parts) == 3:
        y = parts[0][-2:]
        m = parts[1].zfill(2)
        d = parts[2].zfill(2)
        return f"{y}{m}{d}"
    if len(parts) == 2:
        # 2ê°œ ë¶€í’ˆë§Œ ìˆìœ¼ë©´ í˜„ì¬ ì—°ë„ ê°€ì • (ì˜ˆ: '2/15')
        y = str(datetime.now(KST).year)[-2:]
        m = parts[0].zfill(2)
        d = parts[1].zfill(2)
        return f"{y}{m}{d}"
    return ""

def get_exif_date(filepath):
    """JPG íŒŒì¼ì˜ EXIF DateTimeOriginalì—ì„œ ë‚ ì§œ ì¶”ì¶œ â†’ 'YYYY-MM-DD'"""
    try:
        img = Image.open(filepath)
        exif = img._getexif()
        if exif:
            for tag_id, value in exif.items():
                if TAGS.get(tag_id) == 'DateTimeOriginal':
                    return value[:10].replace(':', '-')
    except Exception:
        pass
    return None

def validate_exif_dates(source_folder, shoot_date, customer_name):
    """EXIF ì´¬ì˜ì¼ ê²€ì¦: ì „ì²´ ì‚¬ì§„ ì¤‘ 90% ì´ìƒ ë‚ ì§œ ì¼ì¹˜í•´ì•¼ í†µê³¼"""
    all_jpg = list(source_folder.rglob('*.jpg')) + list(source_folder.rglob('*.JPG'))
    all_jpg = [f for f in all_jpg if '@eaDir' not in str(f) and not f.name.startswith('.')]
    if not all_jpg:
        return True, 0, 0  # ì‚¬ì§„ ì—†ìœ¼ë©´ í†µê³¼ (ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ìŠ¤í‚µë¨)

    # shoot_dateë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    normalized = normalize_date(shoot_date)
    if len(normalized) == 6:
        target_date = f"20{normalized[:2]}-{normalized[2:4]}-{normalized[4:6]}"
    else:
        target_date = None

    if not target_date:
        logger.warning(f"{customer_name}: ì´¬ì˜ì¼ íŒŒì‹± ë¶ˆê°€ â†’ EXIF ê²€ì¦ ìŠ¤í‚µ")
        return True, len(all_jpg), 0

    match_count = 0
    for jpg in all_jpg:
        exif_date = get_exif_date(jpg)
        if exif_date == target_date:
            match_count += 1

    total = len(all_jpg)
    ratio = match_count / total if total > 0 else 0
    pct = int(ratio * 100)
    folder_name = source_folder.name

    if ratio >= 0.9:
        logger.info(f"[ê²€ì¦ í†µê³¼] {customer_name} | ì´¬ì˜ì¼: {normalized} | í´ë”: {folder_name} | ì‚¬ì§„: {total}ì¥ | EXIF ë‚ ì§œ ì¼ì¹˜: {match_count}/{total} ({pct}%)")
        return True, total, match_count
    else:
        logger.warning(f"[ê²€ì¦ ì‹¤íŒ¨] {customer_name} | ì´¬ì˜ì¼: {normalized} | í´ë”: {folder_name} | EXIF ë‚ ì§œ ì¼ì¹˜: {match_count}/{total} ({pct}%) â†’ ìŠ¤í‚µ")
        return False, total, match_count

def is_name_match(masked_name, full_name):
    if masked_name == full_name:
        return True
    if len(masked_name) >= 2 and len(full_name) >= 2:
        if masked_name in full_name or full_name in masked_name:
            return True
    if '*' in masked_name:
        pattern = masked_name.replace('*', '.')
        if re.match(pattern, full_name):
            return True
    if '*' in full_name:
        pattern = full_name.replace('*', '.')
        if re.match(pattern, masked_name):
            return True
    if len(masked_name) >= 2 and len(full_name) >= 2:
        if masked_name[0] == full_name[0] and masked_name[-1] == full_name[-1]:
            return True
    return False

def create_customer_folder(base_folder, date_str, customer_name):
    folder_name = f"{date_str}_{customer_name}"
    folder_path = base_folder / folder_name
    folder_path.mkdir(parents=True, exist_ok=True)
    return folder_path

def parse_google_time(time_str):
    try:
        if 'T' in time_str:
            if '+' in time_str or time_str.endswith('Z'):
                dt = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
            else:
                dt = datetime.fromisoformat(time_str).replace(tzinfo=KST)
            return dt.astimezone(KST)
    except Exception as e:
        logger.warning(f"ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {time_str} - {e}")
    return None

def parse_export_filename_time(filename):
    match = re.search(r'(\d{4})(\d{2})(\d{2})_(\d{2})(\d{2})(\d{2})', filename)
    if match:
        try:
            return datetime(
                int(match.group(1)), int(match.group(2)), int(match.group(3)),
                int(match.group(4)), int(match.group(5)), int(match.group(6)),
                tzinfo=KST
            )
        except ValueError:
            pass
    return None

# ============================================================
# Phase 1: ì›ë³¸/ë‚´ë³´ë‚´ê¸° ì •ë¦¬
# ============================================================
def scan_photo_folder(folder, label=""):
    if not folder.exists():
        logger.warning(f"{label} í´ë” ì—†ìŒ: {folder}")
        return []
    files = []
    for f in folder.iterdir():
        if f.is_file() and not f.name.startswith('.') and not f.name.startswith('@'):
            files.append(f)
    logger.info(f"{label}: {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
    return files

def move_photos_for_appointment(files, start_time, end_time, dest_folder, label=""):
    buffer = timedelta(minutes=TIME_BUFFER_MINUTES)
    range_start = start_time - buffer
    range_end = end_time + buffer
    moved = 0
    for f in files:
        try:
            file_time = parse_export_filename_time(f.name)
            if file_time is None:
                mtime = os.path.getmtime(str(f))
                file_time = datetime.fromtimestamp(mtime, tz=KST)
            if range_start <= file_time <= range_end:
                dest = dest_folder / f.name
                counter = 1
                while dest.exists():
                    stem = f.stem
                    dest = dest_folder / f"{stem}_{counter}{f.suffix}"
                    counter += 1
                shutil.move(str(f), str(dest))
                moved += 1
        except Exception as e:
            logger.error(f"íŒŒì¼ ì´ë™ ì‹¤íŒ¨ {f.name}: {e}")
    if moved > 0:
        logger.info(f"{label}: {moved}ì¥ ì´ë™ ì™„ë£Œ â†’ {dest_folder.name}")
    return moved

def process_appointments(service):
    now = datetime.now(KST)
    time_min = (now - timedelta(hours=PAST_HOURS_LIMIT)).isoformat()
    time_max = (now + timedelta(hours=PAST_HOURS_LIMIT)).isoformat()
    try:
        events_result = service.events().list(
            calendarId=CALENDAR_ID,
            timeMin=time_min, timeMax=time_max,
            singleEvents=True, orderBy='startTime'
        ).execute()
        events = events_result.get('items', [])
    except Exception as e:
        logger.error(f"ìº˜ë¦°ë” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    if not events:
        logger.info("ì˜ˆì•½ ì—†ìŒ")
        return []
    events.reverse()
    original_files = scan_photo_folder(ORIGINAL_FOLDER, "ì›ë³¸ì‚¬ì§„")
    export_files = scan_photo_folder(EXPORT_FOLDER, "ë‚´ë³´ë‚´ê¸°")
    total_original = 0
    total_export = 0
    processed_events = []
    for event in events:
        summary = event.get('summary', 'unknown')
        start_str = event.get('start', {}).get('dateTime', '')
        end_str = event.get('end', {}).get('dateTime', '')
        start_time = parse_google_time(start_str)
        end_time = parse_google_time(end_str)
        if not start_time or not end_time:
            logger.warning(f"ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨, ê±´ë„ˆëœ€: {summary}")
            continue
        customer_name = sanitize_customer_name(summary)
        date_str = start_time.strftime('%y%m%d')
        grade = 'í”„ë¦¬ë¯¸ì—„' if ('í”„ë¦¬ë¯¸ì—„' in summary or 'premium' in summary.lower()) else 'ë² ì´ì§'
        folder_label = f"{customer_name}_{grade}"
        customer_folder = create_customer_folder(CLIENTS_FOLDER, date_str, folder_label)
        orig_moved = move_photos_for_appointment(
            original_files, start_time, end_time,
            customer_folder, f"ì›ë³¸â†’{customer_name}"
        )
        total_original += orig_moved
        export_subfolder = customer_folder / 'ë‚´ë³´ë‚´ê¸°'
        export_subfolder.mkdir(exist_ok=True)
        exp_moved = move_photos_for_appointment(
            export_files, start_time, end_time,
            export_subfolder, f"ë‚´ë³´ë‚´ê¸°â†’{customer_name}"
        )
        total_export += exp_moved
        processed_events.append({
            'summary': summary, 'customer_name': customer_name,
            'start_time': start_time, 'end_time': end_time, 'date_str': date_str
        })
    logger.info(f"ì •ë¦¬ ì™„ë£Œ: ì›ë³¸ {total_original}ì¥, ë‚´ë³´ë‚´ê¸° {total_export}ì¥ ì´ë™")
    return processed_events

# ============================================================
# Phase 2: ë² ì´ì§/í”„ë¦¬ë¯¸ì—„ ë°œì†¡ ì¡°íšŒ
# ============================================================
def get_pending_basic(sheets_service, config):
    """ë² ì´ì§ ì‹œíŠ¸ì—ì„œ Dì—´(ë¦¬ë·°í™•ì¸) ì²´í¬ ìˆê³  Eì—´(ì›ë³¸ë°œì†¡) ë¹„ì–´ìˆëŠ” ê±´ ì¡°íšŒ"""
    sheet_id = config['ledger_sheet_id']
    try:
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=sheet_id, range=BASIC_SHEET_RANGE
        ).execute()
        rows = result.get('values', [])
    except Exception as e:
        logger.error(f"ë² ì´ì§ ì‹œíŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    pending = []
    for i, row in enumerate(rows):
        shoot_date = row[0].strip() if len(row) > 0 else ''
        customer_name = row[1].strip() if len(row) > 1 else ''
        phone = row[2].strip() if len(row) > 2 else ''
        review_done = row[3].strip() if len(row) > 3 else ''
        original_sent = row[4].strip() if len(row) > 4 else ''
        if customer_name and review_done and not original_sent:
            if not phone:
                logger.info(f"{customer_name}: ì „í™”ë²ˆí˜¸ ë¯¸ì…ë ¥ â†’ ë°œì†¡ ëŒ€ê¸°")
                continue
            pending.append({
                'row_index': i + 2,
                'customer_name': customer_name,
                'phone': phone,
                'shoot_date': shoot_date,
            })
    logger.info(f"ë² ì´ì§ ë°œì†¡ ëŒ€ê¸°: {len(pending)}ê±´")
    return pending

def get_pending_premium(sheets_service, config):
    """í”„ë¦¬ë¯¸ì—„ ì‹œíŠ¸ì—ì„œ 1ì°¨/2ì°¨ ë°œì†¡ ëŒ€ê¸° ê±´ ì¡°íšŒ
    ì»¬ëŸ¼: A:ì´¬ì˜ì¼, B:ê³ ê°ì´ë¦„, C:ì „í™”ë²ˆí˜¸, D:ì£¼ì†Œ,
          E:1ì°¨ë°œì†¡(ì›ë³¸+êµ¬ê¸€í¼), F:ë³´ì •ìš”ì²­ì¼, G:ë³´ì •ì™„ë£Œ,
          H:2ì°¨ë°œì†¡(ë³´ì •ë³¸), I:ìµœì¢…ì»¨íŒì¼, J:ë¹„ê³ 
    """
    sheet_id = config['ledger_sheet_id']
    try:
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=sheet_id, range=PREMIUM_SHEET_RANGE
        ).execute()
        rows = result.get('values', [])
    except Exception as e:
        logger.error(f"í”„ë¦¬ë¯¸ì—„ ì‹œíŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return [], []
    first_pending = []   # 1ì°¨ ë°œì†¡ ëŒ€ê¸°
    second_pending = []  # 2ì°¨ ë°œì†¡ ëŒ€ê¸°
    for i, row in enumerate(rows):
        shoot_date = row[0].strip() if len(row) > 0 else ''
        customer_name = row[1].strip() if len(row) > 1 else ''
        phone = row[2].strip() if len(row) > 2 else ''
        address = row[3].strip() if len(row) > 3 else ''
        first_sent = row[4].strip() if len(row) > 4 else ''    # Eì—´: 1ì°¨ë°œì†¡
        retouch_done = row[6].strip() if len(row) > 6 else ''  # Gì—´: ë³´ì •ì™„ë£Œ
        second_sent = row[7].strip() if len(row) > 7 else ''   # Hì—´: 2ì°¨ë°œì†¡
        # 1ì°¨: 1ì°¨ë°œì†¡(Eì—´) ë¹„ì–´ìˆëŠ” ê±´ (ì „í™”ë²ˆí˜¸ ì—†ìœ¼ë©´ ìŠ¤í‚µ)
        if customer_name and not first_sent and not phone:
            logger.info(f"{customer_name}: ì „í™”ë²ˆí˜¸ ë¯¸ì…ë ¥ â†’ ë°œì†¡ ëŒ€ê¸°")
        elif customer_name and phone and not first_sent:
            first_pending.append({
                'row_index': i + 2,
                'customer_name': customer_name,
                'phone': phone,
                'shoot_date': shoot_date,
                'address': address,
                'delivery_type': 'first',
            })
        # 2ì°¨: ë³´ì •ì™„ë£Œ(Gì—´)ì— ê°’ ìˆê³  2ì°¨ë°œì†¡(Hì—´) ë¹„ì–´ìˆëŠ” ê±´
        if customer_name and retouch_done and not second_sent:
            second_pending.append({
                'row_index': i + 2,
                'customer_name': customer_name,
                'phone': phone,
                'shoot_date': shoot_date,
                'address': address,
                'delivery_type': 'second',
            })
    logger.info(f"í”„ë¦¬ë¯¸ì—„ 1ì°¨ ë°œì†¡ ëŒ€ê¸°: {len(first_pending)}ê±´, 2ì°¨ ë°œì†¡ ëŒ€ê¸°: {len(second_pending)}ê±´")
    return first_pending, second_pending

def find_delivery_folder(customer_name, shoot_date=None, delivery_type='original'):
    """ë°œì†¡ìš© í´ë” íƒìƒ‰: delivery_type ì— ë”°ë¼ 'ë‚´ë³´ë‚´ê¸°' ë˜ëŠ” 'ë³´ì •ë³¸' ìš°ì„  íƒìƒ‰"""
    normalized_shoot = normalize_date(shoot_date) if shoot_date else ''
    
    # 1ìˆœìœ„: Console í´ë” (ì£¼ë¡œ ë² ì´ì§/í”„ë¦¬ë¯¸ì—„ 1ì°¨ ì›ë³¸)
    # 2ìˆœìœ„: í”„ë¦¬ë¯¸ì—„ ì‘ì—… í´ë” (ì£¼ë¡œ í”„ë¦¬ë¯¸ì—„ 2ì°¨ ë³´ì •ë³¸)
    search_paths = [CLIENTS_FOLDER, PREMIUM_FOLDER]
    
    for base_folder in search_paths:
        if not base_folder.exists():
            continue
            
        for folder in base_folder.iterdir():
            if not folder.is_dir() or folder.name.startswith('@') or folder.name.startswith('0'):
                continue
            
            # ë‚ ì§œ ë§¤ì¹­
            folder_date = folder.name[:6]
            if normalized_shoot and folder_date != normalized_shoot:
                continue
            
            # ì´ë¦„ ë§¤ì¹­
            folder_parts = re.sub(r'^\d{6}_', '', folder.name).strip()
            folder_customer = re.split(r'[\s_]', folder_parts)[0].strip()
            
            if is_name_match(customer_name, folder_customer):
                # delivery_typeì— ë”°ë¥¸ í•˜ìœ„ í´ë” ìš°ì„  ìˆœìœ„
                if delivery_type == 'retouched':
                    target_sub = folder / RETOUCH_SUBFOLDER  # 'ë³´ì •ë³¸'
                else:
                    target_sub = folder / 'ë‚´ë³´ë‚´ê¸°'
                
                if target_sub.exists():
                    jpgs = list(target_sub.glob('*.jpg')) + list(target_sub.glob('*.JPG'))
                    jpgs = [f for f in jpgs if not f.name.startswith('.')]
                    if jpgs:
                        logger.info(f"ëŒ€ìƒ í´ë” ë°œê²¬ ({delivery_type}): {folder.name}/{target_sub.name} ({len(jpgs)}ì¥)")
                        return target_sub
                
                # ì°¨ì„ ì±…: ë‹¤ë¥¸ í•˜ìœ„ í´ë”ë„ í™•ì¸
                other_sub = folder / 'ë‚´ë³´ë‚´ê¸°' if delivery_type == 'retouched' else folder / RETOUCH_SUBFOLDER
                if other_sub.exists():
                    jpgs = list(other_sub.glob('*.jpg')) + list(other_sub.glob('*.JPG'))
                    jpgs = [f for f in jpgs if not f.name.startswith('.')]
                    if jpgs:
                        logger.info(f"ëŒ€ìƒ í´ë” ë°œê²¬ (ì°¨ì„ ): {folder.name}/{other_sub.name} ({len(jpgs)}ì¥)")
                        return other_sub

                # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: í´ë” ì „ì²´ íƒìƒ‰
                all_jpg = list(folder.rglob('*.jpg')) + list(folder.rglob('*.JPG'))
                all_jpg = [f for f in all_jpg if '@eaDir' not in str(f) and not f.name.startswith('.')]
                if all_jpg:
                    logger.info(f"ëŒ€ìƒ í´ë” ë°œê²¬ (ì „ì²´ íƒìƒ‰): {folder.name} ({len(all_jpg)}ì¥)")
                    return folder
    
    logger.warning(f"ë°œì†¡ ëŒ€ìƒ í´ë” ì—†ìŒ: {customer_name} ({delivery_type})")
    return None

def zip_folder(folder_path, zip_name):
    """í•˜ìœ„ í´ë” êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ë©° ZIP ìƒì„±"""
    zip_path = Path('/tmp') / zip_name
    logger.info(f"ZIP ì••ì¶• ì‹œì‘: {folder_path} â†’ {zip_path}")
    with zipfile.ZipFile(str(zip_path), 'w', zipfile.ZIP_DEFLATED) as zf:
        for file in sorted(folder_path.rglob('*')):
            if file.is_file() and '@eaDir' not in str(file) and not file.name.startswith('.'):
                arcname = file.relative_to(folder_path)
                zf.write(str(file), str(arcname))
    size_mb = zip_path.stat().st_size / (1024 * 1024)
    logger.info(f"ZIP ìƒì„± ì™„ë£Œ: {zip_name} ({size_mb:.0f}MB)")
    return zip_path

def upload_to_firebase(bucket, zip_path, customer_name):
    """Firebase Storageì— ì§ì ‘ ì—…ë¡œë“œ"""
    blob_path = f"auto/{customer_name}/{zip_path.name}"
    blob = bucket.blob(blob_path)
    
    logger.info(f"Firebase Storage ì—…ë¡œë“œ ì‹œì‘: {zip_path.name} ({zip_path.stat().st_size / (1024*1024):.0f}MB)")
    
    blob.upload_from_filename(str(zip_path), content_type='application/zip')
    
    # ì„œëª…ëœ ë‹¤ìš´ë¡œë“œ URL ìƒì„± (15ì¼ ìœ íš¨)
    from datetime import timedelta as td
    url = blob.generate_signed_url(expiration=td(days=15), method='GET')
    
    logger.info(f"Firebase ì—…ë¡œë“œ ì™„ë£Œ: {blob_path}")
    return url

def create_download_page(config, customer_name, shoot_date, original_url, page_type='original'):
    """bdaystudio.storeì— ê³ ê° ë‹¤ìš´ë¡œë“œ í˜ì´ì§€ ìë™ ìƒì„±"""
    api_url = config['bdaystudio_api_url']
    api_key = config['bdaystudio_api_key']
    create_url = f"{api_url}/api/auto-create"
    
    # shoot_date í˜•ì‹ ë³€í™˜ â†’ YYYY-MM-DD (ê³µë°±/ì /í•˜ì´í”ˆ/ìŠ¬ë˜ì‹œ ëª¨ë‘ ì²˜ë¦¬)
    import re as _re
    digits = _re.sub(r'[^0-9]', '', shoot_date)
    if len(digits) == 6:
        formatted_date = f"20{digits[:2]}-{digits[2:4]}-{digits[4:6]}"
    elif len(digits) == 8:
        formatted_date = f"{digits[:4]}-{digits[4:6]}-{digits[6:8]}"
    elif len(digits) == 7:
        # ì˜ˆ: 2026215 -> 2026-02-15
        year = digits[:4]
        month = digits[4:5].zfill(2) if len(digits[4:]) == 3 else digits[4:6].zfill(2)
        day = digits[-2:].zfill(2)
        # 7ìë¦¬ëŠ” ëª¨í˜¸í•˜ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì›ë³¸ ìœ ì§€ í›„ ê¸°í˜¸ë§Œ êµì²´í•˜ëŠ” ë°©ì‹ ë³‘í–‰
        formatted_date = shoot_date.replace(' ', '').replace('.', '-').replace('/', '-')
    else:
        formatted_date = shoot_date.replace(' ', '').replace('.', '-').replace('/', '-')
    
    # ë§ˆì§€ë§‰ìœ¼ë¡œ í•œ ë²ˆ ë” í™•ì¸: í˜¹ì‹œë¼ë„ ìŠ¬ë˜ì‹œê°€ ë‚¨ì•„ìˆìœ¼ë©´ í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½ (Firestore ê²½ë¡œ ì˜¤ë¥˜ ë°©ì§€)
    formatted_date = formatted_date.replace('/', '-')
    
    payload = {
        'customerName': customer_name,
        'shootDate': formatted_date,
        'type': page_type,
        'originalUrl': original_url if page_type == 'original' else '',
        'retouchedUrl': original_url if page_type == 'retouched' else '',
        'videoUrl': '',
        'calendarUrl': ''
    }
    
    resp = requests.post(
        create_url,
        headers={
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        },
        json=payload,
        timeout=30
    )
    
    if resp.status_code != 200:
        raise Exception(f"í˜ì´ì§€ ìƒì„± ì‹¤íŒ¨ ({resp.status_code}): {resp.text}")
    
    result = resp.json()
    download_url = result.get('downloadUrl', '')
    logger.info(f"ë‹¤ìš´ë¡œë“œ í˜ì´ì§€ ìƒì„±: {download_url}")
    return download_url

def update_sheet_cell(sheets_service, config, sheet_name, col, row_index, value):
    """ì‹œíŠ¸ì˜ íŠ¹ì • ì…€ì— ê°’ ì—…ë°ì´íŠ¸"""
    sheet_id = config['ledger_sheet_id']
    cell_range = f'{sheet_name}!{col}{row_index}'
    try:
        sheets_service.spreadsheets().values().update(
            spreadsheetId=sheet_id,
            range=cell_range,
            valueInputOption='USER_ENTERED',
            body={'values': [[value]]}
        ).execute()
        logger.info(f"ì‹œíŠ¸ ì—…ë°ì´íŠ¸: {cell_range} â† {value[:30]}..." if len(str(value)) > 30 else f"ì‹œíŠ¸ ì—…ë°ì´íŠ¸: {cell_range} â† {value}")
    except Exception as e:
        logger.error(f"ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {cell_range}: {e}")

def _upload_and_create_page(bucket, config, customer_name, shoot_date, source_folder, page_type):
    """EXIF ê²€ì¦ â†’ ZIP ì••ì¶• â†’ Firebase ì—…ë¡œë“œ â†’ ë‹¤ìš´ë¡œë“œ í˜ì´ì§€ ìƒì„± (ê³µí†µ ë¡œì§)"""
    # í•˜ìœ„ í´ë” í¬í•¨ ì „ì²´ JPG ì¹´ìš´íŠ¸
    all_jpg = list(source_folder.rglob('*.jpg')) + list(source_folder.rglob('*.JPG'))
    all_jpg = [f for f in all_jpg if '@eaDir' not in str(f) and not f.name.startswith('.')]
    photo_count = len(all_jpg)
    if photo_count == 0:
        logger.warning(f"{customer_name}: JPG íŒŒì¼ ì—†ìŒ â†’ ìŠ¤í‚µ")
        return None

    # EXIF ì´¬ì˜ì¼ ê²€ì¦ (90% ê¸°ì¤€)
    passed, total, matched = validate_exif_dates(source_folder, shoot_date, customer_name)
    if not passed:
        return None

    today_str = datetime.now(KST).strftime('%y%m%d')
    zip_name = f"ìŠ¤íŠœë””ì˜¤ìƒì¼_{customer_name}_{today_str}.zip"
    zip_path = None
    try:
        zip_path = zip_folder(source_folder, zip_name)
        file_url = upload_to_firebase(bucket, zip_path, customer_name)
        download_url = create_download_page(config, customer_name, shoot_date, file_url, page_type=page_type)
        return download_url
    except Exception as e:
        logger.error(f"{customer_name}: ì—…ë¡œë“œ/í˜ì´ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None
    finally:
        if zip_path and zip_path.exists():
            zip_path.unlink()

# ============================================================
# ì•Œë¦¼ ê¸°ëŠ¥
# ============================================================
def send_telegram_message(config, message):
    """í…”ë ˆê·¸ë¨ ë´‡ì„ í†µí•´ ë©”ì‹œì§€ ì „ì†¡"""
    token = config.get('telegram_bot_token')
    chat_id = config.get('telegram_chat_id')
    if not token or not chat_id:
        return

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload = {'chat_id': chat_id, 'text': message, 'parse_mode': 'HTML'}
    try:
        resp = requests.post(url, json=payload, timeout=10)
        if resp.status_code != 200:
            logger.error(f"í…”ë ˆê·¸ë¨ ë°œì†¡ ì‹¤íŒ¨ ({resp.status_code}): {resp.text}")
    except Exception as e:
        logger.error(f"í…”ë ˆê·¸ë¨ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

def notify_delivery(config, customer_name, delivery_type, download_url):
    """ë°œì†¡ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡"""
    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ êµ¬ì„±
    if 'premium' in delivery_type or 'retouched' in delivery_type or 'first' in delivery_type:
        grade = 'í”„ë¦¬ë¯¸ì—„'
    else:
        grade = 'ë² ì´ì§'
        
    if 'retouched' in delivery_type or 'second' in delivery_type:
        phase = '2ì°¨ (ë³´ì •ë³¸)'
    else:
        phase = '1ì°¨ (ì›ë³¸)'
    
    msg = (
        f"<b>[ìŠ¤íŠœë””ì˜¤ìƒì¼ ë°œì†¡ ì•Œë¦¼]</b>\n\n"
        f"ğŸ“ <b>ê³ ê°ëª…:</b> {customer_name}\n"
        f"ğŸ“ <b>ë¶„ë¥˜:</b> {grade} ({phase})\n"
        f"ğŸ”— <b>ë‹¤ìš´ë¡œë“œ:</b> {download_url}\n"
        f"âš ï¸ <b>ë§Œë£Œì¼:</b> ë°œì†¡ í›„ 7ì¼ ì´ë‚´ (ì´í›„ ìë™ ì‚­ì œ)\n\n"
        f"ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ë° ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    )
    
    send_telegram_message(config, msg)

def cleanup_firebase_storage(bucket, config):
    """ì„¤ì •ëœ ê¸°ê°„(7ì¼)ì´ ì§€ë‚œ ì—…ë¡œë“œ íŒŒì¼ ìë™ ì‚­ì œ"""
    retention_days = config.get('storage_retention_days', 7)
    logger.info(f"Firebase Storage ì •ë¦¬ ì‹œì‘ (ë³´ê´€ ê¸°ê°„: {retention_days}ì¼)...")
    
    count = 0
    now = datetime.now(timezone.utc)
    
    try:
        # auto/ í´ë” ë‚´ íŒŒì¼ ë¦¬ìŠ¤íŒ…
        blobs = bucket.list_blobs(prefix='auto/')
        for blob in blobs:
            # blob.time_createdëŠ” timezone-aware (UTC)
            age = now - blob.time_created
            if age.days >= retention_days:
                logger.info(f"[Storage ì‚­ì œ] ì˜¤ë˜ëœ íŒŒì¼ ì œê±°: {blob.name} (ìƒì„±ì¼: {blob.time_created})")
                blob.delete()
                count += 1
                
        if count > 0:
            logger.info(f"âœ… Storage ì •ë¦¬ ì™„ë£Œ: {count}ê°œ íŒŒì¼ ì‚­ì œë¨")
        else:
            logger.info("Storage ì •ë¦¬: ì‚­ì œí•  ì˜¤ë˜ëœ íŒŒì¼ ì—†ìŒ")
            
    except Exception as e:
        logger.error(f"Storage ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        notify_error(config, "Storage ì •ë¦¬", str(e))

def notify_error(config, component, error_detail):
    """ì¥ì•  ë°œìƒ ì‹œ ì•Œë¦¼ ì „ì†¡"""
    msg = (
        f"ğŸš¨ <b>[ìŠ¤íŠœë””ì˜¤ìƒì¼ ì‹œìŠ¤í…œ ì¥ì• ]</b>\n\n"
        f"ğŸ“ <b>ìœ„ì¹˜:</b> {component}\n"
        f"âŒ <b>ë‚´ìš©:</b> {error_detail}\n\n"
        f"ì¦‰ê°ì ì¸ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    )
    send_telegram_message(config, msg)

# ============================================================
# Phase 2-A: ë² ì´ì§ ì›ë³¸ ë°œì†¡
# ============================================================
def process_basic_deliveries():
    logger.info("ë² ì´ì§ ì›ë³¸ ë°œì†¡ ì²˜ë¦¬ ì‹œì‘...")
    try:
        config = load_config()
        sheets_service = get_sheets_service()
    except Exception as e:
        logger.error(f"API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    api_url = config.get('bdaystudio_api_url', '')
    api_key = config.get('bdaystudio_api_key', '')
    if not api_url or not api_key:
        logger.error("config.jsonì— bdaystudio_api_url ë˜ëŠ” bdaystudio_api_keyê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    try:
        bucket = init_firebase()
    except Exception as e:
        logger.error(f"Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    pending = get_pending_basic(sheets_service, config)
    if not pending:
        logger.info("ë² ì´ì§ ë°œì†¡ ëŒ€ê¸° ê±´ ì—†ìŒ")
        return

    for item in pending:
        customer_name = item['customer_name']
        phone = item['phone']
        shoot_date = item['shoot_date']
        row_index = item['row_index']

        logger.info(f"[ë² ì´ì§] ì²˜ë¦¬ ì¤‘: {customer_name} ({phone})")

        source_folder = find_delivery_folder(customer_name, shoot_date, 'original')
        if not source_folder:
            logger.warning(f"[ë² ì´ì§] {customer_name}: í´ë” ì—†ìŒ â†’ ìŠ¤í‚µ")
            continue

        download_url = _upload_and_create_page(bucket, config, customer_name, shoot_date, source_folder, 'original')
        if not download_url:
            continue

        update_sheet_cell(sheets_service, config, 'ë² ì´ì§', 'E', row_index, download_url)
        
        # ì•Œë¦¼ ì „ì†¡
        notify_delivery(config, customer_name, 'basic', download_url)
        
        logger.info(f"âœ… [ë² ì´ì§] {customer_name} ì™„ë£Œ! â†’ {download_url}")
        logger.info(f"   ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ìœ„ ë§í¬ë¥¼ ì „ì†¡í•˜ì„¸ìš”")

# ============================================================
# Phase 2-B: í”„ë¦¬ë¯¸ì—„ 1ì°¨/2ì°¨ ë°œì†¡
# ============================================================
def process_premium_deliveries():
    logger.info("í”„ë¦¬ë¯¸ì—„ ë°œì†¡ ì²˜ë¦¬ ì‹œì‘...")
    try:
        config = load_config()
        sheets_service = get_sheets_service()
    except Exception as e:
        logger.error(f"API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    api_url = config.get('bdaystudio_api_url', '')
    api_key = config.get('bdaystudio_api_key', '')
    if not api_url or not api_key:
        logger.error("config.jsonì— bdaystudio_api_url ë˜ëŠ” bdaystudio_api_keyê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    google_form_url = config.get('google_form_url', '')

    try:
        bucket = init_firebase()
    except Exception as e:
        logger.error(f"Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    first_pending, second_pending = get_pending_premium(sheets_service, config)

    # --- 1ì°¨ ë°œì†¡: ì›ë³¸ + êµ¬ê¸€í¼ ë§í¬ ---
    for item in first_pending:
        customer_name = item['customer_name']
        phone = item['phone']
        shoot_date = item['shoot_date']
        row_index = item['row_index']

        logger.info(f"[í”„ë¦¬ë¯¸ì—„ 1ì°¨] ì²˜ë¦¬ ì¤‘: {customer_name} ({phone})")

        source_folder = find_delivery_folder(customer_name, shoot_date, 'original')
        if not source_folder:
            logger.warning(f"[í”„ë¦¬ë¯¸ì—„ 1ì°¨] {customer_name}: í´ë” ì—†ìŒ â†’ ìŠ¤í‚µ")
            continue

        download_url = _upload_and_create_page(bucket, config, customer_name, shoot_date, source_folder, 'original')
        if not download_url:
            continue

        update_sheet_cell(sheets_service, config, 'í”„ë¦¬ë¯¸ì—„', 'E', row_index, download_url)

        # ì•Œë¦¼ ì „ì†¡
        notify_delivery(config, customer_name, 'premium_first', download_url)

        logger.info(f"âœ… [í”„ë¦¬ë¯¸ì—„ 1ì°¨] {customer_name} ì™„ë£Œ!")
        logger.info(f"   ë‹¤ìš´ë¡œë“œ ë§í¬: {download_url}")
        if google_form_url:
            logger.info(f"   êµ¬ê¸€í¼ ë§í¬: {google_form_url}")
            logger.info(f"   ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ìœ„ ë‘ ë§í¬ë¥¼ í•¨ê»˜ ì „ì†¡í•˜ì„¸ìš”")
        else:
            logger.info(f"   ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ìœ„ ë§í¬ë¥¼ ì „ì†¡í•˜ì„¸ìš”")

    # --- 2ì°¨ ë°œì†¡: ë³´ì •ë³¸ ---
    for item in second_pending:
        customer_name = item['customer_name']
        phone = item['phone']
        shoot_date = item['shoot_date']
        row_index = item['row_index']

        logger.info(f"[í”„ë¦¬ë¯¸ì—„ 2ì°¨] ì²˜ë¦¬ ì¤‘: {customer_name} ({phone})")

        source_folder = find_delivery_folder(customer_name, shoot_date, 'retouched')
        if not source_folder:
            logger.warning(f"[í”„ë¦¬ë¯¸ì—„ 2ì°¨] {customer_name}: ë³´ì •ë³¸ í´ë” ì—†ìŒ â†’ ìŠ¤í‚µ")
            continue

        download_url = _upload_and_create_page(bucket, config, customer_name, shoot_date, source_folder, 'retouched')
        if not download_url:
            continue

        update_sheet_cell(sheets_service, config, 'í”„ë¦¬ë¯¸ì—„', 'H', row_index, download_url)
        
        # ì•Œë¦¼ ì „ì†¡
        notify_delivery(config, customer_name, 'premium_retouched', download_url)
        
        logger.info(f"âœ… [í”„ë¦¬ë¯¸ì—„ 2ì°¨] {customer_name} ì™„ë£Œ! â†’ {download_url}")
        logger.info(f"   ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ìœ„ ë§í¬ë¥¼ ì „ì†¡í•˜ì„¸ìš”")

# ============================================================
# Phase 0: ìº˜ë¦°ë” â†’ ì‹œíŠ¸ ìë™ ë“±ë¡
# ============================================================
def parse_calendar_event(event):
    """ìº˜ë¦°ë” ì´ë²¤íŠ¸ì—ì„œ ê³ ê° ì •ë³´ íŒŒì‹±
    ì œëª© ì˜ˆ: 'ì‚¬ê³µ*ì§€ (2ëª…) (í”„ë¦¬ë¯¸ì—„)'
    ë³¸ë¬¸ ì˜ˆ:
        ì˜ˆì•½ ìƒí’ˆ: ì…€í”„ì´¬ì˜ ì˜ˆì•½
        ë„¤ì´ë²„ ì˜ˆì•½ì: ì‚¬ê³µ*ì§€
        ì´ ì¸ì›: 2ëª…
        ë“±ê¸‰ ë° ì˜µì…˜: (í”„ë¦¬ë¯¸ì—„)
    """
    summary = event.get('summary', '')
    description = event.get('description', '')
    start_str = event.get('start', {}).get('dateTime', '')
    start_time = parse_google_time(start_str)

    # ì œëª©ì—ì„œ íŒŒì‹±: "ì‚¬ê³µ*ì§€ (2ëª…) (í”„ë¦¬ë¯¸ì—„)"
    name_match = re.match(r'^([^\(]+)', summary)
    customer_name = name_match.group(1).strip() if name_match else summary.strip()

    people_match = re.search(r'\((\d+)ëª…\)', summary)
    num_people = people_match.group(1) if people_match else '1'

    if 'í”„ë¦¬ë¯¸ì—„' in summary or 'premium' in summary.lower():
        grade = 'í”„ë¦¬ë¯¸ì—„'
    elif 'ë² ì´ì§' in summary or 'basic' in summary.lower():
        grade = 'ë² ì´ì§'
    else:
        grade = 'ë² ì´ì§'  # ë“±ê¸‰ í‘œì‹œ ì—†ìœ¼ë©´ ë² ì´ì§

    # descriptionì—ì„œ ë³´ì™„ (ì œëª©ì—ì„œ ëª» ì½ì€ ê²½ìš°)
    if description:
        if not people_match:
            desc_people = re.search(r'ì´\s*ì¸ì›\s*[:ï¼š]?\s*(\d+)ëª…', description)
            if desc_people:
                num_people = desc_people.group(1)

        desc_grade = re.search(r'ë“±ê¸‰[^:ï¼š]*[:ï¼š]?\s*\(?(í”„ë¦¬ë¯¸ì—„|ë² ì´ì§)\)?', description)
        if desc_grade:
            grade = desc_grade.group(1)

    shoot_date = start_time.strftime('%Y. %-m. %-d') if start_time else ''
    reservation_time = start_time.strftime('%H:%M') if start_time else ''

    return {
        'customer_name': customer_name,
        'num_people': num_people,
        'grade': grade,
        'shoot_date': shoot_date,
        'reservation_time': reservation_time,
    }


def _get_sheet_rows(sheets_service, sheet_id, range_str):
    """ì‹œíŠ¸ì—ì„œ í–‰ ë°ì´í„° ì¡°íšŒ"""
    try:
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=sheet_id, range=range_str
        ).execute()
        return result.get('values', [])
    except Exception as e:
        logger.error(f"ì‹œíŠ¸ ì¡°íšŒ ì‹¤íŒ¨ ({range_str}): {e}")
        return []


def sync_calendar_to_sheets(calendar_service, sheets_service, config):
    """ìº˜ë¦°ë” ì´ë²¤íŠ¸ë¥¼ ì‹œíŠ¸ì— ìë™ ë“±ë¡ (ì¤‘ë³µ ì‹œ ìŠ¤í‚µ)"""
    logger.info("ìº˜ë¦°ë” â†’ ì‹œíŠ¸ ìë™ ë“±ë¡ ì‹œì‘...")
    now = datetime.now(KST)
    time_min = (now - timedelta(hours=PAST_HOURS_LIMIT)).isoformat()
    time_max = (now + timedelta(hours=PAST_HOURS_LIMIT)).isoformat()

    try:
        events_result = calendar_service.events().list(
            calendarId=CALENDAR_ID,
            timeMin=time_min, timeMax=time_max,
            singleEvents=True, orderBy='startTime'
        ).execute()
        events = events_result.get('items', [])
    except Exception as e:
        logger.error(f"ìº˜ë¦°ë” ì¡°íšŒ ì‹¤íŒ¨ (ì‹œíŠ¸ ë“±ë¡): {e}")
        return

    if not events:
        logger.info("ì‹œíŠ¸ ë“±ë¡: ì˜ˆì•½ ì´ë²¤íŠ¸ ì—†ìŒ")
        return

    sheet_id = config['ledger_sheet_id']

    # ê¸°ì¡´ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ
    basic_rows = _get_sheet_rows(sheets_service, sheet_id, BASIC_SHEET_RANGE)
    premium_rows = _get_sheet_rows(sheets_service, sheet_id, PREMIUM_SHEET_RANGE)

    registered_count = 0
    skipped_count = 0

    for event in events:
        info = parse_calendar_event(event)
        if not info['customer_name']:
            continue

        target_sheet = 'í”„ë¦¬ë¯¸ì—„' if info['grade'] == 'í”„ë¦¬ë¯¸ì—„' else 'ë² ì´ì§'
        existing_rows = premium_rows if info['grade'] == 'í”„ë¦¬ë¯¸ì—„' else basic_rows

        # ì¤‘ë³µ í™•ì¸ (ì´¬ì˜ì¼ + ê³ ê°ëª…)
        normalized_shoot = normalize_date(info['shoot_date'])
        already_exists = False
        for row in existing_rows:
            row_date = normalize_date(row[0]) if len(row) > 0 else ''
            row_name = row[1].strip() if len(row) > 1 else ''
            if row_date == normalized_shoot and is_name_match(info['customer_name'], row_name):
                already_exists = True
                break

        if already_exists:
            logger.info(f"[ì‹œíŠ¸ ë“±ë¡] {info['customer_name']}: ì´ë¯¸ {target_sheet} ì‹œíŠ¸ì— ì¡´ì¬ â†’ ìŠ¤í‚µ")
            skipped_count += 1
            continue

        # ìƒˆ í–‰ ì¶”ê°€ (ì „í™”ë²ˆí˜¸ ì¹¸ì€ ë¹„ì›Œë‘ )
        if target_sheet == 'ë² ì´ì§':
            # A:ì´¬ì˜ì¼, B:ê³ ê°ì´ë¦„, C:ì „í™”ë²ˆí˜¸, D:ë¦¬ë·°í™•ì¸, E:ì›ë³¸ë°œì†¡, F:ë¹„ê³ 
            new_row = [info['shoot_date'], info['customer_name'], '', '', '', f"{info['num_people']}ëª…"]
            append_range = 'ë² ì´ì§!A:F'
        else:
            # A:ì´¬ì˜ì¼, B:ê³ ê°ì´ë¦„, C:ì „í™”ë²ˆí˜¸, D:ì£¼ì†Œ, E~I:ë°œì†¡ê´€ë ¨, J:ë¹„ê³ 
            new_row = [info['shoot_date'], info['customer_name'], '', '', '', '', '', '', '', f"{info['num_people']}ëª…"]
            append_range = 'í”„ë¦¬ë¯¸ì—„!A:J'

        try:
            sheets_service.spreadsheets().values().append(
                spreadsheetId=sheet_id,
                range=append_range,
                valueInputOption='USER_ENTERED',
                insertDataOption='INSERT_ROWS',
                body={'values': [new_row]}
            ).execute()
            logger.info(f"âœ… [ì‹œíŠ¸ ë“±ë¡] {info['customer_name']} ({info['grade']}, {info['num_people']}ëª…) â†’ {target_sheet} ì‹œíŠ¸ì— ì¶”ê°€ ì™„ë£Œ")
            registered_count += 1

            # ë¡œì»¬ ìºì‹œì—ë„ ì¶”ê°€ (ë™ì¼ ì‹¤í–‰ ì¤‘ ì¤‘ë³µ ë°©ì§€)
            existing_rows.append(new_row)
        except Exception as e:
            logger.error(f"[ì‹œíŠ¸ ë“±ë¡] {info['customer_name']}: í–‰ ì¶”ê°€ ì‹¤íŒ¨: {e}")

    logger.info(f"ì‹œíŠ¸ ë“±ë¡ ì™„ë£Œ: ì‹ ê·œ {registered_count}ê±´, ìŠ¤í‚µ {skipped_count}ê±´")


# ============================================================
# ë©”ì¸
# ============================================================
def main():
    logger.info("=" * 60)
    logger.info("ìŠ¤íŠœë””ì˜¤ìƒì¼ ìë™í™” v6.0 ì‹œì‘ (ìº˜ë¦°ë”â†’ì‹œíŠ¸ ë“±ë¡ + ì›ë³¸/ë‚´ë³´ë‚´ê¸° + ë² ì´ì§/í”„ë¦¬ë¯¸ì—„ ë°œì†¡)")
    logger.info(f"ì„¤ì •: ê³¼ê±° {PAST_HOURS_LIMIT}ì‹œê°„ ì˜ˆì•½ ì²˜ë¦¬, ë²„í¼ Â±{TIME_BUFFER_MINUTES}ë¶„")

    # [v6.0] ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ (File Lock)
    if LOCK_FILE.exists():
        # íŒŒì¼ì´ ìˆì§€ë§Œ í”„ë¡œì„¸ìŠ¤ê°€ ì£½ì—ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ìƒì„± ì‹œê°„ ì²´í¬ (ì„ íƒ ì‚¬í•­)
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí•˜ê²Œ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë¼ê³  íŒë‹¨í•˜ê³  ì¢…ë£Œ
        logger.warning(f"âš ï¸ ì´ë¯¸ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (Lock íŒŒì¼ ë°œê²¬: {LOCK_FILE})")
        return

    try:
        # Lock íŒŒì¼ ìƒì„±
        with open(LOCK_FILE, 'w') as f:
            f.write(str(os.getpid()))
        
        try:
            service = None
            try:
                service = get_calendar_service()
                processed_events = process_appointments(service)
            except Exception as e:
                logger.error(f"ì˜ˆì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            # ìº˜ë¦°ë” â†’ ì‹œíŠ¸ ìë™ ë“±ë¡
            try:
                sheets_svc = get_sheets_service()
                config = load_config()
                if service:
                    sync_calendar_to_sheets(service, sheets_svc, config)
                else:
                    logger.warning("Calendar ì„œë¹„ìŠ¤ ì—†ìŒ â†’ ì‹œíŠ¸ ìë™ ë“±ë¡ ìŠ¤í‚µ")
            except Exception as e:
                logger.error(f"ì‹œíŠ¸ ìë™ ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {e}")

            try:
                process_basic_deliveries()
            except Exception as e:
                logger.error(f"ë² ì´ì§ ë°œì†¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            try:
                process_premium_deliveries()
            except Exception as e:
                logger.error(f"í”„ë¦¬ë¯¸ì—„ ë°œì†¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            # Firebase Storage ì •ë¦¬ (v5.9 ì¶”ê°€)
            try:
                bucket = init_firebase()
                cleanup_firebase_storage(bucket, config)
            except Exception as e:
                logger.error(f"Storage ì •ë¦¬ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")

            logger.info("ì „ì²´ ìë™í™” ì™„ë£Œ!")
        except Exception as e:
            logger.error(f"ë©”ì¸ ë£¨í‹´ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            try:
                config = load_config()
                notify_error(config, "ë©”ì¸ ì‹œìŠ¤í…œ", str(e))
            except:
                pass
    finally:
        # Lock íŒŒì¼ ì œê±°
        if LOCK_FILE.exists():
            LOCK_FILE.unlink()
        
    logger.info("=" * 60)

if __name__ == '__main__':
    main()
