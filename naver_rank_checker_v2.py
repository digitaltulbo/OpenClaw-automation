# -*- coding: utf-8 -*-
import subprocess, re, sys, json, urllib.parse

TARGET = "ìŠ¤íŠœë””ì˜¤ìƒì¼"
COMPETITORS = ["ì˜¤ëŠ˜, ìš°ë¦¬ ì‚¬ì§„ê´€", "ì˜¤ëŠ˜ìš°ë¦¬"]
KEYWORDS = ["ë¶„ë‹¹ ì…€í”„ì‚¬ì§„ê´€", "ì•¼íƒ‘ ì‚¬ì§„ê´€", "ì•¼íƒ‘ ì…€í”„ì‚¬ì§„ê´€"]

def strip_html(text):
    """Remove ALL HTML tags and entities from text"""
    text = re.sub(r'<[^>]+>', '', text)           # <mark>, </mark>, etc.
    text = re.sub(r'\\u003[Cc][^;]*;?', '', text) # unicode escaped tags
    text = re.sub(r'&[a-zA-Z]+;', '', text)       # &amp; etc.
    return text.strip()

def fetch_naver_html(keyword):
    encoded_kw = urllib.parse.quote(keyword)
    url = f"https://m.search.naver.com/search.naver?query={encoded_kw}"
    cmd = ["curl", "-s", "-L", "-A", "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)", url]
    try:
        return subprocess.run(cmd, capture_output=True, text=True, timeout=10).stdout
    except: return ""

def parse_place_rankings(html):
    rankings = []
    seen_names = set()
    
    items = html.split('<li class="BX')[1:]
    for block in items[:20]:
        name_search = re.search(r'<span>([^<]+)</span>', block)
        if not name_search: continue
        raw_name = name_search.group(1).strip()
        name = strip_html(raw_name)
        
        if not name or name in ['MY','ë³€ê²½','ë”ë³´ê¸°','ë„¤ì´ë²„']: continue
        if 'place_bluelink' not in block and 'tit' not in block: continue
        if name in seen_names: continue  # Skip duplicates
        seen_names.add(name)

        is_us = TARGET in name
        is_competitor = any(c in name for c in COMPETITORS)
        
        review_count = 0
        rv_match = re.search(r'(?:ë¦¬ë·°|ë°©ë¬¸ìë¦¬ë·°)\s*(\d+,?\d*)', block)
        if rv_match:
            try: review_count = int(rv_match.group(1).replace(',',''))
            except: pass
            
        rankings.append({
            "rank": len(rankings) + 1,
            "name": name,
            "reviews": review_count,
            "is_us": is_us,
            "is_competitor": is_competitor
        })
        if len(rankings) >= 10: break
    
    if not rankings:
        matches = re.findall(r'"name":"([^"]+)"', html)
        for raw in matches[:50]:
            name = strip_html(raw)
            if name in seen_names: continue
            if any(x in name for x in ['ì‚¬ì§„','ìŠ¤íŠœë””ì˜¤','í¬í† ','ì…€í”„']):
                seen_names.add(name)
                rankings.append({"rank": len(rankings)+1, "name": name, "reviews": 0,
                    "is_us": TARGET in name, "is_competitor": any(c in name for c in COMPETITORS)})
                if len(rankings) >= 10: break
    return rankings

if __name__ == "__main__":
    if "--json" in sys.argv:
        results = []
        for kw in KEYWORDS:
            ranks = parse_place_rankings(fetch_naver_html(kw))
            our = next((r["rank"] for r in ranks if r["is_us"]), 0)
            results.append({"keyword": kw, "our_rank": our, "rankings": ranks})
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        for kw in KEYWORDS:
            ranks = parse_place_rankings(fetch_naver_html(kw))
            print(f"\nğŸ“Œ '{kw}' ê²€ìƒ‰ ê²°ê³¼:")
            if not ranks: print("  (ë°ì´í„° ì—†ìŒ)")
            for item in ranks:
                marker = " ğŸ‘‰ ìš°ë¦¬" if item["is_us"] else (" ğŸ¯" if item["is_competitor"] else "")
                rev = f" (ë¦¬ë·° {item['reviews']})" if item['reviews'] > 0 else ""
                print(f"  {item['rank']}ìœ„: {item['name']}{rev}{marker}")
